{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XQyTEgCiMlQE"
   },
   "source": [
    "# Assignment 1: Decision Trees and Nearest Neighbor Classification\n",
    " \n",
    "In this assignment you will explore the use of decision trees and nearest neighbor classifiers to learn morphological classes. You will make use of standard implementations of these classifiers in scikit learn.\n",
    " \n",
    "Provided are two word morphology data sets describing the formation of inflected word forms from lemma information for the plural forms of German nouns (german_plural.arff) and the past tense forms of English verbs (english_past_tense.arff), respectively. You will evaluate two classifiers, decision trees and k nearest neighbours, for predicting the class from test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HWkYzx0vvsTA"
   },
   "source": [
    "The data is in the arff format, which is the standard format of the machine learning package Weka, and more or less self-explanatory. If you want to know more about the format, consult the Weka documentation (https://www.cs.waikato.ac.nz/ml/weka/).\n",
    "\n",
    "The files can be downloaded from the student portal or from the given urls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q_wdMb5IT6X_"
   },
   "outputs": [],
   "source": [
    "data_urls = [\"\"\"https://cl.lingfil.uu.se/~frewa417/english_past_tense.arff\"\"\", \"\"\"https://cl.lingfil.uu.se/~frewa417/german_plural.arff\"\"\"]\n",
    "\n",
    "filenames = [url.split(\"/\")[-1] for url in data_urls]\n",
    "\n",
    "import urllib.request\n",
    "for url, fn in zip(data_urls, filenames):\n",
    "  urllib.request.urlretrieve(url, fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zaHHAcHfNSfa"
   },
   "source": [
    "The two data files should now be downloaded. We can see if this is the case by running a shell command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "TzOHRNRVNR9b",
    "outputId": "ebcb196f-e67e-42ef-cd7b-db35b5b5ddca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english_past_tense.arff  german_plural.arff  sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a6wUjcnONYQ0"
   },
   "source": [
    "## Data Exploration\n",
    "\n",
    "Your first task is to get acquainted with the data sets.\n",
    "\n",
    "\n",
    "The first data set contains 25168 instances, each of which is a German noun lemma, and that each instance has 9 attributes, of which the class attributes encode the plural formation of the noun and is the attribute that we want to learn to predict. The attribute **frequency** records corpus frequency, the attribute **gender** represents the gender of the noun, and the attributes **p1-p6** give a phonological representation of the last two syllables of the base form. Specifically, p1, p2 and p3 represent the onset, nucleus and coda of the penultimate syllable, and p4, p5 and p6 those of the ultimate syllable. By selecting different attributes, you can inspect their type, value set and distribution in the data set.\n",
    "\n",
    "Next the *English past tense data set*, which consists of 4330 verb lemmas and where the class to predict is the past tense formation rule. Attributes are similar to the ones found in the German data set, except that the phonological representation covers the last three syllables (p1-p3: antepenultimate, p4-p6: penultimate, p7-p9: ultimate) and that there is no gender attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BfseBuawPdQj"
   },
   "source": [
    "The data files are in an uncompressed text format. The first part describes the data (note that all features are categorical) and the second part is the data points. We can look at the first 20 lines of both files using the **head** shell command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "colab_type": "code",
    "id": "bnoLLZSrJlTm",
    "outputId": "e42b8fbd-f19d-4144-91ff-9d763ab61296"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@relation plural\n",
      "@attribute frequency NUMERIC\n",
      "@attribute p1 {+, +l, +r, -, =, =l, =v, J, N, S, Sl, Sm, Sn, Sp, Spl, Spr, Sr, St, Str, Sv, Z, _, b, bl, br, d, dl, dm, dn, dr, f, fl, fr, g, gl, gm, gn, gr, h, j, k, kl, kn, kr, ks, kv, l, m, n, p, pj, pl, pn, pr, ps, pt, r, s, s=, sf, sk, skl, skr, sl, sm, sp, st, stj, str, sv, t, tl, tn, tr, v, vj, x, z}\n",
      "@attribute p2 {#, &, ), -, /, 0, 1, 2, 6, @, B, E, I, O, U, W, X, Y, a, e, i, o, q, u, y, |, ~}\n",
      "@attribute p3 {+, -, =, =t, J, N, Nk, Nkt, Ns, Nst, Nt, S, d, f, f=, fs, ft, k, ks, kst, kt, l, l=, lS, lf, lfs, lk, lks, lm, lp, lps, lpst, ls, lst, lt, lx, m, m+, m=, mf, mp, ms, mt, n, n=, nJ, nS, nd, nf, nf=, nft, ns, nst, nt, ntl, nx, p, ps, pst, pt, r, r=, rS, rf, rk, rkt, rl, rm, rn, rnst, rp, rpst, rs, rst, rt, rx, s, sp, st, t, x, x=, xs, xst, xt}\n",
      "@attribute p4 {+, +l, +r, -, =, =l, =v, J, N, Nl, S, Sl, Sm, Sn, Sp, Spl, Spr, Sr, St, Str, Sv, Z, _, _m, b, bl, br, d, dl, dn, dr, f, fj, fl, fr, ft, g, gl, gm, gn, gr, h, j, k, kl, kn, kr, ks, kv, l, m, ml, n, p, pl, pn, pr, ps, r, s, s=, sf, sk, skr, skv, sl, sn, sp, sr, st, str, sv, t, tl, tn, tr, tv, v, vj, vr, x, xl, z, zn} \n",
      "@attribute p5 {#, $, &, ), /, 0, 4, @, B, E, I, O, U, W, X, Y, ^, a, e, i, o, q, u, y, (, |, ~}\n",
      "@attribute p6 {+, -, =, J, N, Nk, Nks, Nkt, Nst, S, Z, _, b, f, ft, k, ks, kst, kt, l, l=, lf, lk, lm, lp, lps, ls, lst, lt, lx, m, m+, mS, mf, mp, mps, ms, mt, n, n=, nJ, nS, nd, nf, nft, ns, nst, nt, nx, p, ps, pst, pt, r, r=, r=t, rS, rf, rft, rk, rkt, rl, rm, rn, rp, rpst, rpt, rs, rst, rt, rx, s, sk, st, t, v, x, x=, xt}\n",
      "@attribute gender {-, F, FM, FN, M, MF, MN, N, NF, NM}\n",
      "@attribute class {-, U, Ue, Uer, e, en, er, s}\n",
      "\n",
      "@data\n",
      "11,l,a,-,d,U,N,F,en\n",
      "2,k,/,-,x,@,r,M,-\n",
      "10,t,o,n,-,a,rt,F,en\n",
      "11,h,E,N,z,@,l,N,-\n",
      "2,-,-,-,kn,&,st,M,e\n",
      "0,-,e,-,r,@,-,F,en\n",
      "0,t,e,-,br,a,t,M,en\n",
      "59,g,@,-,v,I,xt,N,e\n"
     ]
    }
   ],
   "source": [
    "!head -n20 german_plural.arff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "colab_type": "code",
    "id": "e2TJ_yc_JOWQ",
    "outputId": "6541b5ea-08d9-4b75-e9b8-ea12151fda05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@relation past-tense\n",
      "@attribute frequency NUMERIC\n",
      "@attribute p1 {=, @, &, 3:, A:, aI, aU, b, bj, bl, bl#, br, d, D, dj, dl#, dn#, dr, dw, dZ, E, E@, eI, f, fj, fl, fl#, fn#, fr, ft, g, gj, gl, gl#, gr, gw, h, hj, i:, I, I@, j, k, kj, kl, kl#, kr, ks, kt, kw, l, ld, ldZ, lf, lj, lk, lm, lp, lpt, ls, lS, lt, ltS, lv, m, mf, mj, ml#, mp, mps, mpt, n, N, nd, ndZ, nj, Nk, nl#, ns, nt, ntS, nz, O, O:, OI, p, pj, pl, pl#, pr, ps, pt, r, r*, s, S, sj, sk, skj, skl, skr, skw, sl, sl#, Sl#, sm, sn, sn#, Sn#, sp, spj, spl, spr, Sr, st, stj, str, sw, t, T, tj, Tj, tl#, tn#, Tn#, tr, Tr, ts, tS, tSr, tw, Tw, u:, U, @U, U@, v, V, vj, vl#, vn#, vz, w, z, Z, zj, zl#, zn#, Zn#}\n",
      "@attribute p2 {=, @, &, 3:, A:, aI, aU, b, bj, bl, bl#, br, d, D, dj, dl#, dn#, dr, dw, dZ, E, E@, eI, f, fj, fl, fl#, fn#, fr, ft, g, gj, gl, gl#, gr, gw, h, hj, i:, I, I@, j, k, kj, kl, kl#, kr, ks, kt, kw, l, ld, ldZ, lf, lj, lk, lm, lp, lpt, ls, lS, lt, ltS, lv, m, mf, mj, ml#, mp, mps, mpt, n, N, nd, ndZ, nj, Nk, nl#, ns, nt, ntS, nz, O, O:, OI, p, pj, pl, pl#, pr, ps, pt, r, r*, s, S, sj, sk, skj, skl, skr, skw, sl, sl#, Sl#, sm, sn, sn#, Sn#, sp, spj, spl, spr, Sr, st, stj, str, sw, t, T, tj, Tj, tl#, tn#, Tn#, tr, Tr, ts, tS, tSr, tw, Tw, u:, U, @U, U@, v, V, vj, vl#, vn#, vz, w, z, Z, zj, zl#, zn#, Zn#}\n",
      "@attribute p3 {=, @, &, 3:, A:, aI, aU, b, bj, bl, bl#, br, d, D, dj, dl#, dn#, dr, dw, dZ, E, E@, eI, f, fj, fl, fl#, fn#, fr, ft, g, gj, gl, gl#, gr, gw, h, hj, i:, I, I@, j, k, kj, kl, kl#, kr, ks, kt, kw, l, ld, ldZ, lf, lj, lk, lm, lp, lpt, ls, lS, lt, ltS, lv, m, mf, mj, ml#, mp, mps, mpt, n, N, nd, ndZ, nj, Nk, nl#, ns, nt, ntS, nz, O, O:, OI, p, pj, pl, pl#, pr, ps, pt, r, r*, s, S, sj, sk, skj, skl, skr, skw, sl, sl#, Sl#, sm, sn, sn#, Sn#, sp, spj, spl, spr, Sr, st, stj, str, sw, t, T, tj, Tj, tl#, tn#, Tn#, tr, Tr, ts, tS, tSr, tw, Tw, u:, U, @U, U@, v, V, vj, vl#, vn#, vz, w, z, Z, zj, zl#, zn#, Zn#}\n",
      "@attribute p4 {=, @, &, 3:, A:, aI, aU, b, bj, bl, bl#, br, d, D, dj, dl#, dn#, dr, dw, dZ, E, E@, eI, f, fj, fl, fl#, fn#, fr, ft, g, gj, gl, gl#, gr, gw, h, hj, i:, I, I@, j, k, kj, kl, kl#, kr, ks, kt, kw, l, ld, ldZ, lf, lj, lk, lm, lp, lpt, ls, lS, lt, ltS, lv, m, mf, mj, ml#, mp, mps, mpt, n, N, nd, ndZ, nj, Nk, nl#, ns, nt, ntS, nz, O, O:, OI, p, pj, pl, pl#, pr, ps, pt, r, r*, s, S, sj, sk, skj, skl, skr, skw, sl, sl#, Sl#, sm, sn, sn#, Sn#, sp, spj, spl, spr, Sr, st, stj, str, sw, t, T, tj, Tj, tl#, tn#, Tn#, tr, Tr, ts, tS, tSr, tw, Tw, u:, U, @U, U@, v, V, vj, vl#, vn#, vz, w, z, Z, zj, zl#, zn#, Zn#}\n",
      "@attribute p5 {=, @, &, 3:, A:, aI, aU, b, bj, bl, bl#, br, d, D, dj, dl#, dn#, dr, dw, dZ, E, E@, eI, f, fj, fl, fl#, fn#, fr, ft, g, gj, gl, gl#, gr, gw, h, hj, i:, I, I@, j, k, kj, kl, kl#, kr, ks, kt, kw, l, ld, ldZ, lf, lj, lk, lm, lp, lpt, ls, lS, lt, ltS, lv, m, mf, mj, ml#, mp, mps, mpt, n, N, nd, ndZ, nj, Nk, nl#, ns, nt, ntS, nz, O, O:, OI, p, pj, pl, pl#, pr, ps, pt, r, r*, s, S, sj, sk, skj, skl, skr, skw, sl, sl#, Sl#, sm, sn, sn#, Sn#, sp, spj, spl, spr, Sr, st, stj, str, sw, t, T, tj, Tj, tl#, tn#, Tn#, tr, Tr, ts, tS, tSr, tw, Tw, u:, U, @U, U@, v, V, vj, vl#, vn#, vz, w, z, Z, zj, zl#, zn#, Zn#}\n",
      "@attribute p6 {=, @, &, 3:, A:, aI, aU, b, bj, bl, bl#, br, d, D, dj, dl#, dn#, dr, dw, dZ, E, E@, eI, f, fj, fl, fl#, fn#, fr, ft, g, gj, gl, gl#, gr, gw, h, hj, i:, I, I@, j, k, kj, kl, kl#, kr, ks, kt, kw, l, ld, ldZ, lf, lj, lk, lm, lp, lpt, ls, lS, lt, ltS, lv, m, mf, mj, ml#, mp, mps, mpt, n, N, nd, ndZ, nj, Nk, nl#, ns, nt, ntS, nz, O, O:, OI, p, pj, pl, pl#, pr, ps, pt, r, r*, s, S, sj, sk, skj, skl, skr, skw, sl, sl#, Sl#, sm, sn, sn#, Sn#, sp, spj, spl, spr, Sr, st, stj, str, sw, t, T, tj, Tj, tl#, tn#, Tn#, tr, Tr, ts, tS, tSr, tw, Tw, u:, U, @U, U@, v, V, vj, vl#, vn#, vz, w, z, Z, zj, zl#, zn#, Zn#}\n",
      "@attribute p7 {=, @, &, 3:, A:, aI, aU, b, bj, bl, bl#, br, d, D, dj, dl#, dn#, dr, dw, dZ, E, E@, eI, f, fj, fl, fl#, fn#, fr, ft, g, gj, gl, gl#, gr, gw, h, hj, i:, I, I@, j, k, kj, kl, kl#, kr, ks, kt, kw, l, ld, ldZ, lf, lj, lk, lm, lp, lpt, ls, lS, lt, ltS, lv, m, mf, mj, ml#, mp, mps, mpt, n, N, nd, ndZ, nj, Nk, nl#, ns, nt, ntS, nz, O, O:, OI, p, pj, pl, pl#, pr, ps, pt, r, r*, s, S, sj, sk, skj, skl, skr, skw, sl, sl#, Sl#, sm, sn, sn#, Sn#, sp, spj, spl, spr, Sr, st, stj, str, sw, t, T, tj, Tj, tl#, tn#, Tn#, tr, Tr, ts, tS, tSr, tw, Tw, u:, U, @U, U@, v, V, vj, vl#, vn#, vz, w, z, Z, zj, zl#, zn#, Zn#}\n",
      "@attribute p8 {=, @, &, 3:, A:, aI, aU, b, bj, bl, bl#, br, d, D, dj, dl#, dn#, dr, dw, dZ, E, E@, eI, f, fj, fl, fl#, fn#, fr, ft, g, gj, gl, gl#, gr, gw, h, hj, i:, I, I@, j, k, kj, kl, kl#, kr, ks, kt, kw, l, ld, ldZ, lf, lj, lk, lm, lp, lpt, ls, lS, lt, ltS, lv, m, mf, mj, ml#, mp, mps, mpt, n, N, nd, ndZ, nj, Nk, nl#, ns, nt, ntS, nz, O, O:, OI, p, pj, pl, pl#, pr, ps, pt, r, r*, s, S, sj, sk, skj, skl, skr, skw, sl, sl#, Sl#, sm, sn, sn#, Sn#, sp, spj, spl, spr, Sr, st, stj, str, sw, t, T, tj, Tj, tl#, tn#, Tn#, tr, Tr, ts, tS, tSr, tw, Tw, u:, U, @U, U@, v, V, vj, vl#, vn#, vz, w, z, Z, zj, zl#, zn#, Zn#}\n",
      "@attribute p9 {=, @, &, 3:, A:, aI, aU, b, bj, bl, bl#, br, d, D, dj, dl#, dn#, dr, dw, dZ, E, E@, eI, f, fj, fl, fl#, fn#, fr, ft, g, gj, gl, gl#, gr, gw, h, hj, i:, I, I@, j, k, kj, kl, kl#, kr, ks, kt, kw, l, ld, ldZ, lf, lj, lk, lm, lp, lpt, ls, lS, lt, ltS, lv, m, mf, mj, ml#, mp, mps, mpt, n, N, nd, ndZ, nj, Nk, nl#, ns, nt, ntS, nz, O, O:, OI, p, pj, pl, pl#, pr, ps, pt, r, r*, s, S, sj, sk, skj, skl, skr, skw, sl, sl#, Sl#, sm, sn, sn#, Sn#, sp, spj, spl, spr, Sr, st, stj, str, sw, t, T, tj, Tj, tl#, tn#, Tn#, tr, Tr, ts, tS, tSr, tw, Tw, u:, U, @U, U@, v, V, vj, vl#, vn#, vz, w, z, Z, zj, zl#, zn#, Zn#}\n",
      "@attribute class { IRREG-aI-aU.,  IRREG-aI-eI.,  IRREG-aI-I.,  IRREG-aI-O:., IRREG-aI-O.,  IRREG-aI-u:.,  IRREG-aI-@U.,  IRREG-aI-V.,  IRREG-CONV., IRREG-@+d.,  IRREG-d-t.,  IRREG-E-&.,  IRREG-eI-u:.,  IRREG-eI-@U., IRREG-eI-U.,  IRREG-E-O.,  IRREG-E@-O:.,  IRREG-I-&.,  IRREG-i:-E., IRREG-i:-E+d.,  IRREG-I-eI.,  IRREG-i:-E+t.,  IRREG-i:-O:., IRREG-i:-@U.,  IRREG-I-U.,  IRREG-I-V.,  IRREG-@+ked.,  IRREG-O:-E., IRREG-OTHER.,  IRREG-O-u.,  IRREG-O:-u:.,  IRREG-@-s+ed.,  IRREG-@+t., IRREG-@U-E.,  IRREG-@U-ju:.,  IRREG-u:-O.,  IRREG-u:-@U., IRREG-@U-u:.,  IRREG-&-V.,  IRREG-V-&.,  IRREG-V-eI.,  REG.}\n",
      "\n",
      "@data\n",
      "975,=,@,=,b,&,n,d,@,n,REG.\n",
      "15,=,=,=,=,@,=,b,&,S,REG.\n",
      "42,=,=,=,=,@,=,b,eI,t,REG.\n",
      "35,br,i:,=,v,I,=,=,eI,t,REG.\n",
      "40,=,&,b,d,I,=,k,eI,t,REG.\n",
      "19,=,=,=,=,@,b,d,V,kt,REG.\n"
     ]
    }
   ],
   "source": [
    "!head -n20 english_past_tense.arff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HcwuQ-NZvwuP"
   },
   "source": [
    "Loading the data files can be done using scipy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w5QYHyObVZ6P"
   },
   "outputs": [],
   "source": [
    "from scipy.io.arff import loadarff\n",
    "loaded_data_files = [loadarff(fn) for fn in filenames]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gxv9Mm2a_TTV"
   },
   "source": [
    "Now you have the data in memory. However, it needs to be re-formated to fit sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PHQygK9YuRJ0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "D = dict()\n",
    "for data in loaded_data_files:\n",
    "  data_points = data[0]\n",
    "  field_names = data[1].names()\n",
    "  assert field_names[0] == 'frequency'\n",
    "  assert field_names[-1] == 'class'\n",
    "  X = list()\n",
    "  y = list()\n",
    "  for point in data_points:\n",
    "    v = [field_names[i]+\"_\"+point[i].decode(\"utf-8\") for i in range(1, len(point)-1)]\n",
    "    X.extend([v]*int(point[0]))\n",
    "    assert len(v) == len(X[0])\n",
    "    u = [point[-1].decode(\"utf-8\")]\n",
    "    y.extend([u]*int(point[0]))\n",
    "    assert len(u) == len(y[0])\n",
    "  assert len(X) == np.sum(np.asarray([point[0] for point in data_points]))\n",
    "  X_orig = np.asarray(X)\n",
    "  y_orig = np.asarray(y).ravel()\n",
    "  D[data[1].name] = tuple([X_orig, y_orig])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IyhNXsIfRAr1"
   },
   "source": [
    "The two data sets are now contained in a dictionary with the following keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "6jiLJ4nnOGZ5",
    "outputId": "3a22c9f8-06d5-4da6-a34e-6c0a304a130a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['past-tense', 'plural'])"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LS3PXzL3RrBl"
   },
   "source": [
    "Each entry in the dictionary is a tuple (X, y) with categorical features. Note that the features are not yet in a numerical format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "colab_type": "code",
    "id": "P9d5Qg1mQj1e",
    "outputId": "35b261c8-cda5-4fcd-f311-1a1aa9f0656e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([['p1_=', 'p2_@', 'p3_=', ..., 'p7_d', 'p8_@', 'p9_n'],\n",
       "        ['p1_=', 'p2_@', 'p3_=', ..., 'p7_d', 'p8_@', 'p9_n'],\n",
       "        ['p1_=', 'p2_@', 'p3_=', ..., 'p7_d', 'p8_@', 'p9_n'],\n",
       "        ...,\n",
       "        ['p1_=', 'p2_=', 'p3_=', ..., 'p7_z', 'p8_u:', 'p9_m'],\n",
       "        ['p1_=', 'p2_=', 'p3_=', ..., 'p7_z', 'p8_u:', 'p9_m'],\n",
       "        ['p1_=', 'p2_=', 'p3_=', ..., 'p7_z', 'p8_u:', 'p9_m']],\n",
       "       dtype='<U6'),\n",
       " array(['REG.', 'REG.', 'REG.', ..., 'REG.', 'REG.', 'REG.'], dtype='<U13'))"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D['past-tense']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "colab_type": "code",
    "id": "fEmDnavnQSlo",
    "outputId": "5cb7c78e-54a9-4a59-f39d-1b699ed03af4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([['p1_l', 'p2_a', 'p3_-', ..., 'p5_U', 'p6_N', 'gender_F'],\n",
       "        ['p1_l', 'p2_a', 'p3_-', ..., 'p5_U', 'p6_N', 'gender_F'],\n",
       "        ['p1_l', 'p2_a', 'p3_-', ..., 'p5_U', 'p6_N', 'gender_F'],\n",
       "        ...,\n",
       "        ['p1_l', 'p2_e', 'p3_-', ..., 'p5_@', 'p6_n', 'gender_N'],\n",
       "        ['p1_l', 'p2_e', 'p3_-', ..., 'p5_@', 'p6_n', 'gender_N'],\n",
       "        ['p1_l', 'p2_e', 'p3_-', ..., 'p5_@', 'p6_n', 'gender_N']],\n",
       "       dtype='<U9'),\n",
       " array(['en', 'en', 'en', ..., '-', '-', '-'], dtype='<U3'))"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D['plural']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v_YvvL3VPMoh"
   },
   "source": [
    "## Making a space using categorical features\n",
    "\n",
    "Your first task is to preprocess the data to be able to analyse it with sklearn. The categorical features need to be converted into proper vectors. This can be done using some preprocessing tools from sklearn. The OneHotEncoder will transform a multiple output category into a set of binary feature dimensions. Using this might make the preprocessed feature vectors very long. (Note that older versions of sklearn do not support this.)\n",
    "\n",
    "```\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "feature_encoder = OneHotEncoder()\n",
    "X = feature_encoder.fit_transform(X_orig)\n",
    "names = feature_encoder.get_feature_names()\n",
    "```\n",
    "\n",
    "Doing a similar encoding for the output data can be done using the LabelEncoder. This encodes the output class labels as numbers. Since we're only interested in the classification accuracy, there is no need for long binary vectors here.\n",
    "\n",
    "```\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y_orig)\n",
    "```\n",
    "\n",
    "Since this is the first lab in this course, you will be given snippets of code to help you along. To have some data to work with, the wine dataset from sklearn will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "gbVXXho5svKf",
    "outputId": "aa55fdab-7197-41c0-9363-a86044aefb4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (178, 13) , y: (178,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "wine = load_wine()\n",
    "X = wine.data\n",
    "y = wine.target\n",
    "print(\"X:\", X.shape, \", y:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "grg-De0nSbDV"
   },
   "source": [
    "## Decision Trees\n",
    "\n",
    "The second task is to induce decision trees for predicting the plural form of a German noun and the past tense form of an English verb. Below, you are given code for how this works for the wine data set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "iMdKazNvESDV",
    "outputId": "0a2798a1-54fd-4e37-d2d0-9ed94c7a7dc7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=2, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(max_depth=2)\n",
    "classifier.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BmrcyKroCBC1"
   },
   "source": [
    "Build decision trees for both language data sets and analyze their performance.\n",
    "\n",
    "Compare training error to test error and see whether there are signs of overfitting. Also, try out some different choices of hyper parameters (especially for [pruning](https://scikit-learn.org/stable/modules/tree.html#minimal-cost-complexity-pruning)) and see how this affects the size of the tree as well as the relation between training and test error. Splitting up the data can be done using the following examples. k-fold cross validation splits up the data and allows you to iterate over different training and test set to mitigate the effect of getting a \"well chosen\" training set by chance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "2jDm9kSyCBf9",
    "outputId": "97bf9820-5bee-4b72-d832-ddb808c9b8c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.1%\n",
      "Accuracy: 77.8%\n",
      "Accuracy: 83.3%\n",
      "Accuracy: 80.0%\n",
      "Accuracy: 91.4%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "for train, test in KFold(n_splits=5, shuffle=True).split(X):\n",
    "  X_train = X[train]\n",
    "  X_test = X[test]\n",
    "  y_train = y[train]\n",
    "  y_test = y[test]\n",
    "  classifier.fit(X_train, y_train)\n",
    "  print(\"Accuracy: %.1f%%\" %(100*classifier.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "DJCwBMQOCsOO",
    "outputId": "3fec9fc3-e048-4355-ad70-9851e806d659"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7,  1,  0],\n",
       "       [ 0, 13,  3],\n",
       "       [ 0,  1, 11]])"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.8)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, classifier.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eacXGLgF-pCi"
   },
   "source": [
    "\n",
    "One of the advantages of decision trees, compared to many other learning algorithms, is that the induced classifier can be interpreted as a set of rules for classifying new instances. Visualising these rules is easy using graphviz (this can also be done using only sklearn but not with the same beautiful result)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "T9bQe4UQ2D1-",
    "outputId": "8ecbad4b-2872-4e77-fac0-e95f21497947"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"594pt\" height=\"314pt\"\n",
       " viewBox=\"0.00 0.00 594.00 314.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 310)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-310 590,-310 590,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#f6fef9\" stroke=\"#000000\" d=\"M352.5,-306C352.5,-306 236.5,-306 236.5,-306 230.5,-306 224.5,-300 224.5,-294 224.5,-294 224.5,-235 224.5,-235 224.5,-229 230.5,-223 236.5,-223 236.5,-223 352.5,-223 352.5,-223 358.5,-223 364.5,-229 364.5,-235 364.5,-235 364.5,-294 364.5,-294 364.5,-300 358.5,-306 352.5,-306\"/>\n",
       "<text text-anchor=\"middle\" x=\"294.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">proline &lt;= 755.0</text>\n",
       "<text text-anchor=\"middle\" x=\"294.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.657</text>\n",
       "<text text-anchor=\"middle\" x=\"294.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 142</text>\n",
       "<text text-anchor=\"middle\" x=\"294.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [51, 55, 36]</text>\n",
       "<text text-anchor=\"middle\" x=\"294.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = class_1</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#aff4cc\" stroke=\"#000000\" d=\"M308,-187C308,-187 51,-187 51,-187 45,-187 39,-181 39,-175 39,-175 39,-116 39,-116 39,-110 45,-104 51,-104 51,-104 308,-104 308,-104 314,-104 320,-110 320,-116 320,-116 320,-175 320,-175 320,-181 314,-187 308,-187\"/>\n",
       "<text text-anchor=\"middle\" x=\"179.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">od280/od315_of_diluted_wines &lt;= 2.205</text>\n",
       "<text text-anchor=\"middle\" x=\"179.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.479</text>\n",
       "<text text-anchor=\"middle\" x=\"179.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 82</text>\n",
       "<text text-anchor=\"middle\" x=\"179.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 51, 30]</text>\n",
       "<text text-anchor=\"middle\" x=\"179.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = class_1</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M254.2786,-222.8796C245.488,-213.7832 236.1034,-204.0722 227.0574,-194.7116\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"229.3591,-192.0568 219.8931,-187.2981 224.3255,-196.9212 229.3591,-192.0568\"/>\n",
       "<text text-anchor=\"middle\" x=\"219.4658\" y=\"-208.5944\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#ea985e\" stroke=\"#000000\" d=\"M469,-187C469,-187 350,-187 350,-187 344,-187 338,-181 338,-175 338,-175 338,-116 338,-116 338,-110 344,-104 350,-104 350,-104 469,-104 469,-104 475,-104 481,-110 481,-116 481,-116 481,-175 481,-175 481,-181 475,-187 469,-187\"/>\n",
       "<text text-anchor=\"middle\" x=\"409.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">flavanoids &lt;= 2.165</text>\n",
       "<text text-anchor=\"middle\" x=\"409.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.291</text>\n",
       "<text text-anchor=\"middle\" x=\"409.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 60</text>\n",
       "<text text-anchor=\"middle\" x=\"409.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [50, 4, 6]</text>\n",
       "<text text-anchor=\"middle\" x=\"409.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = class_0</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>0&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M334.7214,-222.8796C343.512,-213.7832 352.8966,-204.0722 361.9426,-194.7116\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"364.6745,-196.9212 369.1069,-187.2981 359.6409,-192.0568 364.6745,-196.9212\"/>\n",
       "<text text-anchor=\"middle\" x=\"369.5342\" y=\"-208.5944\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#965ae9\" stroke=\"#000000\" d=\"M111,-68C111,-68 12,-68 12,-68 6,-68 0,-62 0,-56 0,-56 0,-12 0,-12 0,-6 6,0 12,0 12,0 111,0 111,0 117,0 123,-6 123,-12 123,-12 123,-56 123,-56 123,-62 117,-68 111,-68\"/>\n",
       "<text text-anchor=\"middle\" x=\"61.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.245</text>\n",
       "<text text-anchor=\"middle\" x=\"61.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 35</text>\n",
       "<text text-anchor=\"middle\" x=\"61.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 5, 30]</text>\n",
       "<text text-anchor=\"middle\" x=\"61.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = class_2</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M135.5612,-103.9815C125.6402,-94.607 115.1103,-84.6572 105.1992,-75.2921\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"107.4334,-72.5878 97.7611,-68.2637 102.6257,-77.6757 107.4334,-72.5878\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"#3de684\" stroke=\"#000000\" d=\"M252,-68C252,-68 153,-68 153,-68 147,-68 141,-62 141,-56 141,-56 141,-12 141,-12 141,-6 147,0 153,0 153,0 252,0 252,0 258,0 264,-6 264,-12 264,-12 264,-56 264,-56 264,-62 258,-68 252,-68\"/>\n",
       "<text text-anchor=\"middle\" x=\"202.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.042</text>\n",
       "<text text-anchor=\"middle\" x=\"202.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 47</text>\n",
       "<text text-anchor=\"middle\" x=\"202.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 46, 0]</text>\n",
       "<text text-anchor=\"middle\" x=\"202.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = class_1</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M188.0644,-103.9815C189.8085,-95.5261 191.6492,-86.6026 193.4109,-78.0623\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"196.8397,-78.7646 195.4322,-68.2637 189.984,-77.3504 196.8397,-78.7646\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<path fill=\"#ab7bee\" stroke=\"#000000\" d=\"M432.5,-68C432.5,-68 340.5,-68 340.5,-68 334.5,-68 328.5,-62 328.5,-56 328.5,-56 328.5,-12 328.5,-12 328.5,-6 334.5,0 340.5,0 340.5,0 432.5,0 432.5,0 438.5,0 444.5,-6 444.5,-12 444.5,-12 444.5,-56 444.5,-56 444.5,-62 438.5,-68 432.5,-68\"/>\n",
       "<text text-anchor=\"middle\" x=\"386.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.375</text>\n",
       "<text text-anchor=\"middle\" x=\"386.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 8</text>\n",
       "<text text-anchor=\"middle\" x=\"386.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 2, 6]</text>\n",
       "<text text-anchor=\"middle\" x=\"386.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = class_2</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M400.9356,-103.9815C399.1915,-95.5261 397.3508,-86.6026 395.5891,-78.0623\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"399.016,-77.3504 393.5678,-68.2637 392.1603,-78.7646 399.016,-77.3504\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<path fill=\"#e68641\" stroke=\"#000000\" d=\"M574,-68C574,-68 475,-68 475,-68 469,-68 463,-62 463,-56 463,-56 463,-12 463,-12 463,-6 469,0 475,0 475,0 574,0 574,0 580,0 586,-6 586,-12 586,-12 586,-56 586,-56 586,-62 580,-68 574,-68\"/>\n",
       "<text text-anchor=\"middle\" x=\"524.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.074</text>\n",
       "<text text-anchor=\"middle\" x=\"524.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 52</text>\n",
       "<text text-anchor=\"middle\" x=\"524.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [50, 2, 0]</text>\n",
       "<text text-anchor=\"middle\" x=\"524.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = class_0</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M452.3218,-103.9815C461.9905,-94.607 472.2527,-84.6572 481.9118,-75.2921\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"484.4176,-77.7375 489.1608,-68.2637 479.5449,-72.7118 484.4176,-77.7375\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7fe8ba61f358>"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "dot_data = export_graphviz(classifier, out_file=None, feature_names=wine.feature_names, \n",
    "                           class_names=wine.target_names, filled=True,\n",
    "                           rounded=True, special_characters=False)\n",
    "graph = graphviz.Source(dot_data)\n",
    "#graph.render(\"wine\")\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MWsj9RxF_EQA"
   },
   "source": [
    "What rules can you find in the trees you have induced? Do they make sense?\n",
    "\n",
    "**Report:**\n",
    "1. How accurate are the decision tree classifiers for the two data sets? Look at overall accuracy as well as precision and recall for specific classes.\n",
    "2. How does training error relate to test error?\n",
    "3. Can you make sense of the rules implicit in the trees? Consider especially the pruned tree for the English past tense data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XjMATs49Sfpp"
   },
   "source": [
    "## K-Nearest Neighbor\n",
    "\n",
    "The third task is to use k-nearest neighbor classification to predict the plural form of a German noun and the past tense form of an English verb.\n",
    "\n",
    "The training part of a knn is simply storing all the training data points. However, for predicitng a class, all pairwise distances between the training and test set must be calculated. There are lots of ways of getting around this time consuming process. Here, you can simply randomly subsample the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "y9AtpjOGCnLb",
    "outputId": "62ef4c74-bb03-4f36-a1b6-aa8e56aa9112"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (18, 13) , y: (18,)\n"
     ]
    }
   ],
   "source": [
    "I = np.random.uniform(0, 1, size=X.shape[0]) < .1\n",
    "X = X[I, :]\n",
    "y = y[I]\n",
    "print(\"X:\", X.shape, \", y:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hJOPyhFjDlk_"
   },
   "source": [
    "The classifier can be used as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "colab_type": "code",
    "id": "AxmcBs3gJ4Ri",
    "outputId": "2e70c905-2343-4986-bd3c-0154d3e18845"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.5, 0. ]),\n",
       " array([1., 0.]),\n",
       " array([0.66666667, 0.        ]),\n",
       " array([1, 1]))"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.9)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(y_test, knn.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lt3XV9kTIgE0"
   },
   "source": [
    "Compare training error to test error. Vary the number of neighbors used to predict the class and see how this affects training and test error. One of the properties of (simple) nearest neighbor classification is that all features are given equal weight, which means that irrelevant features could hurt classification accuracy. Check whether you can improve accuracy by removing features or reweighting samples. Compare the best accuracy to that obtained with decision trees.\n",
    "\n",
    "**Report:**\n",
    "1. How accurate are the nearest neighbor classifiers for the two data sets? Look at overall accuracy as well as precision and recall for specific classes.\n",
    "2. What is the effect of varying the k parameter? Plot the cross validated accuracy vs increasing k.\n",
    "3. Can you improve accuracy by removing less informative features?\n",
    "4. Does k-nearest neighbor perform better or worse than decision trees? Can you force the nearest neighbor classifier to behave like the pruned decision tree on the English past tense data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "utGge3LFSWVd"
   },
   "source": [
    "**Report:** Which features are most informative for the two data sets? Try to explain why some features are more informative than others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YdrPyjBuSps1"
   },
   "source": [
    "## VG assignment\n",
    "\n",
    "The above tasks are sufficient to obtain a pass grade (G) in this assignment. To obtain a pass with distinction (VG), all the assignments must be carried out without major errors, and there is an additional task you should solve.\n",
    "\n",
    "It is fairly obvious that the performance of a machine learning task depends on the amount of training data that is available, but the amount of data required to reach a certain level of performance in a specific task varies. Your last task is to relate the size of the training data to the performance you can achieve on the two data sets.\n",
    "\n",
    "Train your classifiers using the best hyperparameters you found for both prediction tasks on a varying amount of training data ranging from just a few examples to the full data set and test the resulting classifiers for each training set size. Do this for both types of classifiers (decision trees\n",
    "and kNN). Check if you can find a set of hyperparameters that work better for smaller training set size and compare the learning curves. Take a look at the rules in the decision trees for various training set sizes.\n",
    "\n",
    "**Report:** Describe how you ran these experiments and present the resulting learning curves, both in tabular and in graphical form. Report and discuss any interesting observations you made.\n",
    "\n",
    "# Submission\n",
    "\n",
    "You should submit one of the following two options:\n",
    "1. A written report (3-5 pages) in academic english, reporting and rguing for your conclusions on all tasks. All code must be included in an appentix and be well commented. The report should be submitted through Studentportalen.\n",
    "**OR**\n",
    "2. Your cleaned notebook with the relevant code and answers to all the questions. The ipynb-file should be submitted through Studentportalen. The code blocks should reproduce your main findings and be commented either in a text cell or standard code comments.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ML lab 1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
