{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XQyTEgCiMlQE"
   },
   "source": [
    "# Assignment 1: Decision Trees and Nearest Neighbor Classification\n",
    " \n",
    "In this assignment you will explore the use of decision trees and nearest neighbor classifiers to learn morphological classes. You will make use of standard implementations of these classifiers in scikit learn.\n",
    " \n",
    "Provided are two word morphology data sets describing the formation of inflected word forms from lemma information for the plural forms of German nouns (german_plural.arff) and the past tense forms of English verbs (english_past_tense.arff), respectively. You will evaluate two classifiers, decision trees and k nearest neighbours, for predicting the class from test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HWkYzx0vvsTA"
   },
   "source": [
    "The data is in the arff format, which is the standard format of the machine learning package Weka, and more or less self-explanatory. If you want to know more about the format, consult the Weka documentation (https://www.cs.waikato.ac.nz/ml/weka/).\n",
    "\n",
    "The files can be downloaded from the student portal or from the given urls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q_wdMb5IT6X_"
   },
   "outputs": [],
   "source": [
    "data_urls = [\"\"\"https://cl.lingfil.uu.se/~frewa417/english_past_tense.arff\"\"\", \"\"\"https://cl.lingfil.uu.se/~frewa417/german_plural.arff\"\"\"]\n",
    "\n",
    "filenames = [url.split(\"/\")[-1] for url in data_urls]\n",
    "\n",
    "import urllib.request\n",
    "for url, fn in zip(data_urls, filenames):\n",
    "  urllib.request.urlretrieve(url, fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zaHHAcHfNSfa"
   },
   "source": [
    "The two data files should now be downloaded. We can see if this is the case by running a shell command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "TzOHRNRVNR9b",
    "outputId": "ebcb196f-e67e-42ef-cd7b-db35b5b5ddca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assignment_1.ipynb      english_past_tense.arff past tense.pdf\r\n",
      "ML_lab_1.ipynb          german_plural.arff\r\n",
      "ML_lab_1_new.ipynb      past tense\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a6wUjcnONYQ0"
   },
   "source": [
    "## Data Exploration\n",
    "\n",
    "Your first task is to get acquainted with the data sets.\n",
    "\n",
    "\n",
    "The first data set contains 25168 instances, each of which is a German noun lemma, and that each instance has 9 attributes, of which the class attributes encode the plural formation of the noun and is the attribute that we want to learn to predict. The attribute **frequency** records corpus frequency, the attribute **gender** represents the gender of the noun, and the attributes **p1-p6** give a phonological representation of the last two syllables of the base form. Specifically, p1, p2 and p3 represent the onset, nucleus and coda of the penultimate syllable, and p4, p5 and p6 those of the ultimate syllable. By selecting different attributes, you can inspect their type, value set and distribution in the data set.\n",
    "\n",
    "Next the *English past tense data set*, which consists of 4330 verb lemmas and where the class to predict is the past tense formation rule. Attributes are similar to the ones found in the German data set, except that the phonological representation covers the last three syllables (p1-p3: antepenultimate, p4-p6: penultimate, p7-p9: ultimate) and that there is no gender attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BfseBuawPdQj"
   },
   "source": [
    "The data files are in an uncompressed text format. The first part describes the data (note that all features are categorical) and the second part is the data points. We can look at the first 20 lines of both files using the **head** shell command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "colab_type": "code",
    "id": "bnoLLZSrJlTm",
    "outputId": "e42b8fbd-f19d-4144-91ff-9d763ab61296"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@relation plural\r\n",
      "@attribute frequency NUMERIC\r\n",
      "@attribute p1 {+, +l, +r, -, =, =l, =v, J, N, S, Sl, Sm, Sn, Sp, Spl, Spr, Sr, St, Str, Sv, Z, _, b, bl, br, d, dl, dm, dn, dr, f, fl, fr, g, gl, gm, gn, gr, h, j, k, kl, kn, kr, ks, kv, l, m, n, p, pj, pl, pn, pr, ps, pt, r, s, s=, sf, sk, skl, skr, sl, sm, sp, st, stj, str, sv, t, tl, tn, tr, v, vj, x, z}\r\n",
      "@attribute p2 {#, &, ), -, /, 0, 1, 2, 6, @, B, E, I, O, U, W, X, Y, a, e, i, o, q, u, y, |, ~}\r\n",
      "@attribute p3 {+, -, =, =t, J, N, Nk, Nkt, Ns, Nst, Nt, S, d, f, f=, fs, ft, k, ks, kst, kt, l, l=, lS, lf, lfs, lk, lks, lm, lp, lps, lpst, ls, lst, lt, lx, m, m+, m=, mf, mp, ms, mt, n, n=, nJ, nS, nd, nf, nf=, nft, ns, nst, nt, ntl, nx, p, ps, pst, pt, r, r=, rS, rf, rk, rkt, rl, rm, rn, rnst, rp, rpst, rs, rst, rt, rx, s, sp, st, t, x, x=, xs, xst, xt}\r\n",
      "@attribute p4 {+, +l, +r, -, =, =l, =v, J, N, Nl, S, Sl, Sm, Sn, Sp, Spl, Spr, Sr, St, Str, Sv, Z, _, _m, b, bl, br, d, dl, dn, dr, f, fj, fl, fr, ft, g, gl, gm, gn, gr, h, j, k, kl, kn, kr, ks, kv, l, m, ml, n, p, pl, pn, pr, ps, r, s, s=, sf, sk, skr, skv, sl, sn, sp, sr, st, str, sv, t, tl, tn, tr, tv, v, vj, vr, x, xl, z, zn} \r\n",
      "@attribute p5 {#, $, &, ), /, 0, 4, @, B, E, I, O, U, W, X, Y, ^, a, e, i, o, q, u, y, (, |, ~}\r\n",
      "@attribute p6 {+, -, =, J, N, Nk, Nks, Nkt, Nst, S, Z, _, b, f, ft, k, ks, kst, kt, l, l=, lf, lk, lm, lp, lps, ls, lst, lt, lx, m, m+, mS, mf, mp, mps, ms, mt, n, n=, nJ, nS, nd, nf, nft, ns, nst, nt, nx, p, ps, pst, pt, r, r=, r=t, rS, rf, rft, rk, rkt, rl, rm, rn, rp, rpst, rpt, rs, rst, rt, rx, s, sk, st, t, v, x, x=, xt}\r\n",
      "@attribute gender {-, F, FM, FN, M, MF, MN, N, NF, NM}\r\n",
      "@attribute class {-, U, Ue, Uer, e, en, er, s}\r\n",
      "\r\n",
      "@data\r\n",
      "11,l,a,-,d,U,N,F,en\r\n",
      "2,k,/,-,x,@,r,M,-\r\n",
      "10,t,o,n,-,a,rt,F,en\r\n",
      "11,h,E,N,z,@,l,N,-\r\n",
      "2,-,-,-,kn,&,st,M,e\r\n",
      "0,-,e,-,r,@,-,F,en\r\n",
      "0,t,e,-,br,a,t,M,en\r\n",
      "59,g,@,-,v,I,xt,N,e\r\n"
     ]
    }
   ],
   "source": [
    "!head -n20 german_plural.arff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "colab_type": "code",
    "id": "e2TJ_yc_JOWQ",
    "outputId": "6541b5ea-08d9-4b75-e9b8-ea12151fda05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@relation past-tense\n",
      "@attribute frequency NUMERIC\n",
      "@attribute p1 {=, @, &, 3:, A:, aI, aU, b, bj, bl, bl#, br, d, D, dj, dl#, dn#, dr, dw, dZ, E, E@, eI, f, fj, fl, fl#, fn#, fr, ft, g, gj, gl, gl#, gr, gw, h, hj, i:, I, I@, j, k, kj, kl, kl#, kr, ks, kt, kw, l, ld, ldZ, lf, lj, lk, lm, lp, lpt, ls, lS, lt, ltS, lv, m, mf, mj, ml#, mp, mps, mpt, n, N, nd, ndZ, nj, Nk, nl#, ns, nt, ntS, nz, O, O:, OI, p, pj, pl, pl#, pr, ps, pt, r, r*, s, S, sj, sk, skj, skl, skr, skw, sl, sl#, Sl#, sm, sn, sn#, Sn#, sp, spj, spl, spr, Sr, st, stj, str, sw, t, T, tj, Tj, tl#, tn#, Tn#, tr, Tr, ts, tS, tSr, tw, Tw, u:, U, @U, U@, v, V, vj, vl#, vn#, vz, w, z, Z, zj, zl#, zn#, Zn#}\n",
      "@attribute p2 {=, @, &, 3:, A:, aI, aU, b, bj, bl, bl#, br, d, D, dj, dl#, dn#, dr, dw, dZ, E, E@, eI, f, fj, fl, fl#, fn#, fr, ft, g, gj, gl, gl#, gr, gw, h, hj, i:, I, I@, j, k, kj, kl, kl#, kr, ks, kt, kw, l, ld, ldZ, lf, lj, lk, lm, lp, lpt, ls, lS, lt, ltS, lv, m, mf, mj, ml#, mp, mps, mpt, n, N, nd, ndZ, nj, Nk, nl#, ns, nt, ntS, nz, O, O:, OI, p, pj, pl, pl#, pr, ps, pt, r, r*, s, S, sj, sk, skj, skl, skr, skw, sl, sl#, Sl#, sm, sn, sn#, Sn#, sp, spj, spl, spr, Sr, st, stj, str, sw, t, T, tj, Tj, tl#, tn#, Tn#, tr, Tr, ts, tS, tSr, tw, Tw, u:, U, @U, U@, v, V, vj, vl#, vn#, vz, w, z, Z, zj, zl#, zn#, Zn#}\n",
      "@attribute p3 {=, @, &, 3:, A:, aI, aU, b, bj, bl, bl#, br, d, D, dj, dl#, dn#, dr, dw, dZ, E, E@, eI, f, fj, fl, fl#, fn#, fr, ft, g, gj, gl, gl#, gr, gw, h, hj, i:, I, I@, j, k, kj, kl, kl#, kr, ks, kt, kw, l, ld, ldZ, lf, lj, lk, lm, lp, lpt, ls, lS, lt, ltS, lv, m, mf, mj, ml#, mp, mps, mpt, n, N, nd, ndZ, nj, Nk, nl#, ns, nt, ntS, nz, O, O:, OI, p, pj, pl, pl#, pr, ps, pt, r, r*, s, S, sj, sk, skj, skl, skr, skw, sl, sl#, Sl#, sm, sn, sn#, Sn#, sp, spj, spl, spr, Sr, st, stj, str, sw, t, T, tj, Tj, tl#, tn#, Tn#, tr, Tr, ts, tS, tSr, tw, Tw, u:, U, @U, U@, v, V, vj, vl#, vn#, vz, w, z, Z, zj, zl#, zn#, Zn#}\n",
      "@attribute p4 {=, @, &, 3:, A:, aI, aU, b, bj, bl, bl#, br, d, D, dj, dl#, dn#, dr, dw, dZ, E, E@, eI, f, fj, fl, fl#, fn#, fr, ft, g, gj, gl, gl#, gr, gw, h, hj, i:, I, I@, j, k, kj, kl, kl#, kr, ks, kt, kw, l, ld, ldZ, lf, lj, lk, lm, lp, lpt, ls, lS, lt, ltS, lv, m, mf, mj, ml#, mp, mps, mpt, n, N, nd, ndZ, nj, Nk, nl#, ns, nt, ntS, nz, O, O:, OI, p, pj, pl, pl#, pr, ps, pt, r, r*, s, S, sj, sk, skj, skl, skr, skw, sl, sl#, Sl#, sm, sn, sn#, Sn#, sp, spj, spl, spr, Sr, st, stj, str, sw, t, T, tj, Tj, tl#, tn#, Tn#, tr, Tr, ts, tS, tSr, tw, Tw, u:, U, @U, U@, v, V, vj, vl#, vn#, vz, w, z, Z, zj, zl#, zn#, Zn#}\n",
      "@attribute p5 {=, @, &, 3:, A:, aI, aU, b, bj, bl, bl#, br, d, D, dj, dl#, dn#, dr, dw, dZ, E, E@, eI, f, fj, fl, fl#, fn#, fr, ft, g, gj, gl, gl#, gr, gw, h, hj, i:, I, I@, j, k, kj, kl, kl#, kr, ks, kt, kw, l, ld, ldZ, lf, lj, lk, lm, lp, lpt, ls, lS, lt, ltS, lv, m, mf, mj, ml#, mp, mps, mpt, n, N, nd, ndZ, nj, Nk, nl#, ns, nt, ntS, nz, O, O:, OI, p, pj, pl, pl#, pr, ps, pt, r, r*, s, S, sj, sk, skj, skl, skr, skw, sl, sl#, Sl#, sm, sn, sn#, Sn#, sp, spj, spl, spr, Sr, st, stj, str, sw, t, T, tj, Tj, tl#, tn#, Tn#, tr, Tr, ts, tS, tSr, tw, Tw, u:, U, @U, U@, v, V, vj, vl#, vn#, vz, w, z, Z, zj, zl#, zn#, Zn#}\n",
      "@attribute p6 {=, @, &, 3:, A:, aI, aU, b, bj, bl, bl#, br, d, D, dj, dl#, dn#, dr, dw, dZ, E, E@, eI, f, fj, fl, fl#, fn#, fr, ft, g, gj, gl, gl#, gr, gw, h, hj, i:, I, I@, j, k, kj, kl, kl#, kr, ks, kt, kw, l, ld, ldZ, lf, lj, lk, lm, lp, lpt, ls, lS, lt, ltS, lv, m, mf, mj, ml#, mp, mps, mpt, n, N, nd, ndZ, nj, Nk, nl#, ns, nt, ntS, nz, O, O:, OI, p, pj, pl, pl#, pr, ps, pt, r, r*, s, S, sj, sk, skj, skl, skr, skw, sl, sl#, Sl#, sm, sn, sn#, Sn#, sp, spj, spl, spr, Sr, st, stj, str, sw, t, T, tj, Tj, tl#, tn#, Tn#, tr, Tr, ts, tS, tSr, tw, Tw, u:, U, @U, U@, v, V, vj, vl#, vn#, vz, w, z, Z, zj, zl#, zn#, Zn#}\n",
      "@attribute p7 {=, @, &, 3:, A:, aI, aU, b, bj, bl, bl#, br, d, D, dj, dl#, dn#, dr, dw, dZ, E, E@, eI, f, fj, fl, fl#, fn#, fr, ft, g, gj, gl, gl#, gr, gw, h, hj, i:, I, I@, j, k, kj, kl, kl#, kr, ks, kt, kw, l, ld, ldZ, lf, lj, lk, lm, lp, lpt, ls, lS, lt, ltS, lv, m, mf, mj, ml#, mp, mps, mpt, n, N, nd, ndZ, nj, Nk, nl#, ns, nt, ntS, nz, O, O:, OI, p, pj, pl, pl#, pr, ps, pt, r, r*, s, S, sj, sk, skj, skl, skr, skw, sl, sl#, Sl#, sm, sn, sn#, Sn#, sp, spj, spl, spr, Sr, st, stj, str, sw, t, T, tj, Tj, tl#, tn#, Tn#, tr, Tr, ts, tS, tSr, tw, Tw, u:, U, @U, U@, v, V, vj, vl#, vn#, vz, w, z, Z, zj, zl#, zn#, Zn#}\n",
      "@attribute p8 {=, @, &, 3:, A:, aI, aU, b, bj, bl, bl#, br, d, D, dj, dl#, dn#, dr, dw, dZ, E, E@, eI, f, fj, fl, fl#, fn#, fr, ft, g, gj, gl, gl#, gr, gw, h, hj, i:, I, I@, j, k, kj, kl, kl#, kr, ks, kt, kw, l, ld, ldZ, lf, lj, lk, lm, lp, lpt, ls, lS, lt, ltS, lv, m, mf, mj, ml#, mp, mps, mpt, n, N, nd, ndZ, nj, Nk, nl#, ns, nt, ntS, nz, O, O:, OI, p, pj, pl, pl#, pr, ps, pt, r, r*, s, S, sj, sk, skj, skl, skr, skw, sl, sl#, Sl#, sm, sn, sn#, Sn#, sp, spj, spl, spr, Sr, st, stj, str, sw, t, T, tj, Tj, tl#, tn#, Tn#, tr, Tr, ts, tS, tSr, tw, Tw, u:, U, @U, U@, v, V, vj, vl#, vn#, vz, w, z, Z, zj, zl#, zn#, Zn#}\n",
      "@attribute p9 {=, @, &, 3:, A:, aI, aU, b, bj, bl, bl#, br, d, D, dj, dl#, dn#, dr, dw, dZ, E, E@, eI, f, fj, fl, fl#, fn#, fr, ft, g, gj, gl, gl#, gr, gw, h, hj, i:, I, I@, j, k, kj, kl, kl#, kr, ks, kt, kw, l, ld, ldZ, lf, lj, lk, lm, lp, lpt, ls, lS, lt, ltS, lv, m, mf, mj, ml#, mp, mps, mpt, n, N, nd, ndZ, nj, Nk, nl#, ns, nt, ntS, nz, O, O:, OI, p, pj, pl, pl#, pr, ps, pt, r, r*, s, S, sj, sk, skj, skl, skr, skw, sl, sl#, Sl#, sm, sn, sn#, Sn#, sp, spj, spl, spr, Sr, st, stj, str, sw, t, T, tj, Tj, tl#, tn#, Tn#, tr, Tr, ts, tS, tSr, tw, Tw, u:, U, @U, U@, v, V, vj, vl#, vn#, vz, w, z, Z, zj, zl#, zn#, Zn#}\n",
      "@attribute class { IRREG-aI-aU.,  IRREG-aI-eI.,  IRREG-aI-I.,  IRREG-aI-O:., IRREG-aI-O.,  IRREG-aI-u:.,  IRREG-aI-@U.,  IRREG-aI-V.,  IRREG-CONV., IRREG-@+d.,  IRREG-d-t.,  IRREG-E-&.,  IRREG-eI-u:.,  IRREG-eI-@U., IRREG-eI-U.,  IRREG-E-O.,  IRREG-E@-O:.,  IRREG-I-&.,  IRREG-i:-E., IRREG-i:-E+d.,  IRREG-I-eI.,  IRREG-i:-E+t.,  IRREG-i:-O:., IRREG-i:-@U.,  IRREG-I-U.,  IRREG-I-V.,  IRREG-@+ked.,  IRREG-O:-E., IRREG-OTHER.,  IRREG-O-u.,  IRREG-O:-u:.,  IRREG-@-s+ed.,  IRREG-@+t., IRREG-@U-E.,  IRREG-@U-ju:.,  IRREG-u:-O.,  IRREG-u:-@U., IRREG-@U-u:.,  IRREG-&-V.,  IRREG-V-&.,  IRREG-V-eI.,  REG.}\n",
      "\n",
      "@data\n",
      "975,=,@,=,b,&,n,d,@,n,REG.\n",
      "15,=,=,=,=,@,=,b,&,S,REG.\n",
      "42,=,=,=,=,@,=,b,eI,t,REG.\n",
      "35,br,i:,=,v,I,=,=,eI,t,REG.\n",
      "40,=,&,b,d,I,=,k,eI,t,REG.\n",
      "19,=,=,=,=,@,b,d,V,kt,REG.\n"
     ]
    }
   ],
   "source": [
    "!head -n20 english_past_tense.arff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HcwuQ-NZvwuP"
   },
   "source": [
    "Loading the data files can be done using scipy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w5QYHyObVZ6P"
   },
   "outputs": [],
   "source": [
    "from scipy.io.arff import loadarff\n",
    "loaded_data_files = [loadarff(fn) for fn in filenames]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gxv9Mm2a_TTV"
   },
   "source": [
    "Now you have the data in memory. However, it needs to be re-formated to fit sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PHQygK9YuRJ0"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loaded_data_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2c1089c1357d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloaded_data_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mdata_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mfield_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loaded_data_files' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "D = dict()\n",
    "for data in loaded_data_files:\n",
    "  data_points = data[0]\n",
    "  field_names = data[1].names()\n",
    "  assert field_names[0] == 'frequency'\n",
    "  assert field_names[-1] == 'class'\n",
    "  X = list()\n",
    "  y = list()\n",
    "  for point in data_points:\n",
    "    v = [field_names[i]+\"_\"+point[i].decode(\"utf-8\") for i in range(1, len(point)-1)]\n",
    "    X.extend([v]*int(point[0]))\n",
    "    assert len(v) == len(X[0])\n",
    "    u = [point[-1].decode(\"utf-8\")]\n",
    "    y.extend([u]*int(point[0]))\n",
    "    assert len(u) == len(y[0])\n",
    "  assert len(X) == np.sum(np.asarray([point[0] for point in data_points]))\n",
    "  X_orig = np.asarray(X)\n",
    "  y_orig = np.asarray(y).ravel()\n",
    "  D[data[1].name] = tuple([X_orig, y_orig])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IyhNXsIfRAr1"
   },
   "source": [
    "The two data sets are now contained in a dictionary with the following keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "6jiLJ4nnOGZ5",
    "outputId": "3a22c9f8-06d5-4da6-a34e-6c0a304a130a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['past-tense', 'plural'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LS3PXzL3RrBl"
   },
   "source": [
    "Each entry in the dictionary is a tuple (X, y) with categorical features. Note that the features are not yet in a numerical format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "colab_type": "code",
    "id": "P9d5Qg1mQj1e",
    "outputId": "35b261c8-cda5-4fcd-f311-1a1aa9f0656e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['p1_=', 'p2_@', 'p3_=', 'p4_b', 'p5_&', 'p6_n', 'p7_d', 'p8_@',\n",
       "       'p9_n'], dtype='<U6')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D['past-tense'][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "colab_type": "code",
    "id": "fEmDnavnQSlo",
    "outputId": "5cb7c78e-54a9-4a59-f39d-1b699ed03af4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([['p1_l', 'p2_a', 'p3_-', ..., 'p5_U', 'p6_N', 'gender_F'],\n",
       "        ['p1_l', 'p2_a', 'p3_-', ..., 'p5_U', 'p6_N', 'gender_F'],\n",
       "        ['p1_l', 'p2_a', 'p3_-', ..., 'p5_U', 'p6_N', 'gender_F'],\n",
       "        ...,\n",
       "        ['p1_l', 'p2_e', 'p3_-', ..., 'p5_@', 'p6_n', 'gender_N'],\n",
       "        ['p1_l', 'p2_e', 'p3_-', ..., 'p5_@', 'p6_n', 'gender_N'],\n",
       "        ['p1_l', 'p2_e', 'p3_-', ..., 'p5_@', 'p6_n', 'gender_N']],\n",
       "       dtype='<U9'),\n",
       " array(['en', 'en', 'en', ..., '-', '-', '-'], dtype='<U3'))"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D['plural']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v_YvvL3VPMoh"
   },
   "source": [
    "## Making a space using categorical features\n",
    "\n",
    "Your first task is to preprocess the data to be able to analyse it with sklearn. The categorical features need to be converted into proper vectors. This can be done using some preprocessing tools from sklearn. The OneHotEncoder will transform a multiple output category into a set of binary feature dimensions. Using this might make the preprocessed feature vectors very long. (Note that older versions of sklearn do not support this.)\n",
    "\n",
    "```\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "feature_encoder = OneHotEncoder()\n",
    "X = feature_encoder.fit_transform(X_orig)\n",
    "names = feature_encoder.get_feature_names()\n",
    "```\n",
    "\n",
    "Doing a similar encoding for the output data can be done using the LabelEncoder. This encodes the output class labels as numbers. Since we're only interested in the classification accuracy, there is no need for long binary vectors here.\n",
    "\n",
    "```\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y_orig)\n",
    "```\n",
    "\n",
    "Since this is the first lab in this course, you will be given snippets of code to help you along. To have some data to work with, the wine dataset from sklearn will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "gbVXXho5svKf",
    "outputId": "aa55fdab-7197-41c0-9363-a86044aefb4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (178, 13) , y: (178,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "wine = load_wine()\n",
    "X = wine.data\n",
    "y = wine.target\n",
    "print(\"X:\", X.shape, \", y:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "grg-De0nSbDV"
   },
   "source": [
    "## Decision Trees\n",
    "\n",
    "The second task is to induce decision trees for predicting the plural form of a German noun and the past tense form of an English verb. Below, you are given code for how this works for the wine data set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "iMdKazNvESDV",
    "outputId": "0a2798a1-54fd-4e37-d2d0-9ed94c7a7dc7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(max_depth=2)\n",
    "classifier.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BmrcyKroCBC1"
   },
   "source": [
    "Build decision trees for both language data sets and analyze their performance.\n",
    "\n",
    "Compare training error to test error and see whether there are signs of overfitting. Also, try out some different choices of hyper parameters (especially for [pruning](https://scikit-learn.org/stable/modules/tree.html#minimal-cost-complexity-pruning)) and see how this affects the size of the tree as well as the relation between training and test error. Splitting up the data can be done using the following examples. k-fold cross validation splits up the data and allows you to iterate over different training and test set to mitigate the effect of getting a \"well chosen\" training set by chance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "2jDm9kSyCBf9",
    "outputId": "97bf9820-5bee-4b72-d832-ddb808c9b8c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.3%\n",
      "Accuracy: 91.7%\n",
      "Accuracy: 83.3%\n",
      "Accuracy: 85.7%\n",
      "Accuracy: 94.3%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "for train, test in KFold(n_splits=5, shuffle=True).split(X):\n",
    "  X_train = X[train]\n",
    "  X_test = X[test]\n",
    "  y_train = y[train]\n",
    "  y_test = y[test]\n",
    "  classifier.fit(X_train, y_train)\n",
    "  print(\"Accuracy: %.1f%%\" %(100*classifier.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "DJCwBMQOCsOO",
    "outputId": "3fec9fc3-e048-4355-ad70-9851e806d659"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12,  0,  2],\n",
       "       [ 1,  9,  3],\n",
       "       [ 0,  1,  8]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.8)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, classifier.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eacXGLgF-pCi"
   },
   "source": [
    "\n",
    "One of the advantages of decision trees, compared to many other learning algorithms, is that the induced classifier can be interpreted as a set of rules for classifying new instances. Visualising these rules is easy using graphviz (this can also be done using only sklearn but not with the same beautiful result)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "T9bQe4UQ2D1-",
    "outputId": "8ecbad4b-2872-4e77-fac0-e95f21497947"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"573pt\" height=\"300pt\"\n",
       " viewBox=\"0.00 0.00 572.91 300.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 296)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-296 568.91,-296 568.91,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#e4fcee\" stroke=\"black\" d=\"M339.93,-292C339.93,-292 227.97,-292 227.97,-292 221.97,-292 215.97,-286 215.97,-280 215.97,-280 215.97,-226 215.97,-226 215.97,-220 221.97,-214 227.97,-214 227.97,-214 339.93,-214 339.93,-214 345.93,-214 351.93,-220 351.93,-226 351.93,-226 351.93,-280 351.93,-280 351.93,-286 345.93,-292 339.93,-292\"/>\n",
       "<text text-anchor=\"middle\" x=\"283.95\" y=\"-276.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">proline &lt;= 755.0</text>\n",
       "<text text-anchor=\"middle\" x=\"283.95\" y=\"-262.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.657</text>\n",
       "<text text-anchor=\"middle\" x=\"283.95\" y=\"-248.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 142</text>\n",
       "<text text-anchor=\"middle\" x=\"283.95\" y=\"-234.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [45, 58, 39]</text>\n",
       "<text text-anchor=\"middle\" x=\"283.95\" y=\"-220.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = class_1</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#b6f5d1\" stroke=\"black\" d=\"M229.65,-178C229.65,-178 126.26,-178 126.26,-178 120.26,-178 114.26,-172 114.26,-166 114.26,-166 114.26,-112 114.26,-112 114.26,-106 120.26,-100 126.26,-100 126.26,-100 229.65,-100 229.65,-100 235.65,-100 241.65,-106 241.65,-112 241.65,-112 241.65,-166 241.65,-166 241.65,-172 235.65,-178 229.65,-178\"/>\n",
       "<text text-anchor=\"middle\" x=\"177.95\" y=\"-162.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">flavanoids &lt;= 1.4</text>\n",
       "<text text-anchor=\"middle\" x=\"177.95\" y=\"-148.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.495</text>\n",
       "<text text-anchor=\"middle\" x=\"177.95\" y=\"-134.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 91</text>\n",
       "<text text-anchor=\"middle\" x=\"177.95\" y=\"-120.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 55, 34]</text>\n",
       "<text text-anchor=\"middle\" x=\"177.95\" y=\"-106.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = class_1</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M247.77,-213.77C239.16,-204.67 229.88,-194.87 221,-185.48\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"223.39,-182.92 213.97,-178.06 218.3,-187.73 223.39,-182.92\"/>\n",
       "<text text-anchor=\"middle\" x=\"213.28\" y=\"-198.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#ea975b\" stroke=\"black\" d=\"M508.67,-178C508.67,-178 271.24,-178 271.24,-178 265.24,-178 259.24,-172 259.24,-166 259.24,-166 259.24,-112 259.24,-112 259.24,-106 265.24,-100 271.24,-100 271.24,-100 508.67,-100 508.67,-100 514.67,-100 520.67,-106 520.67,-112 520.67,-112 520.67,-166 520.67,-166 520.67,-172 514.67,-178 508.67,-178\"/>\n",
       "<text text-anchor=\"middle\" x=\"389.95\" y=\"-162.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">od280/od315_of_diluted_wines &lt;= 2.64</text>\n",
       "<text text-anchor=\"middle\" x=\"389.95\" y=\"-148.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.276</text>\n",
       "<text text-anchor=\"middle\" x=\"389.95\" y=\"-134.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 51</text>\n",
       "<text text-anchor=\"middle\" x=\"389.95\" y=\"-120.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [43, 3, 5]</text>\n",
       "<text text-anchor=\"middle\" x=\"389.95\" y=\"-106.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = class_0</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>0&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M320.14,-213.77C328.75,-204.67 338.02,-194.87 346.91,-185.48\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"349.6,-187.73 353.93,-178.06 344.52,-182.92 349.6,-187.73\"/>\n",
       "<text text-anchor=\"middle\" x=\"354.62\" y=\"-198.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#975cea\" stroke=\"black\" d=\"M107.86,-64C107.86,-64 12.05,-64 12.05,-64 6.05,-64 0.05,-58 0.05,-52 0.05,-52 0.05,-12 0.05,-12 0.05,-6 6.05,0 12.05,0 12.05,0 107.86,0 107.86,0 113.86,0 119.86,-6 119.86,-12 119.86,-12 119.86,-52 119.86,-52 119.86,-58 113.86,-64 107.86,-64\"/>\n",
       "<text text-anchor=\"middle\" x=\"59.95\" y=\"-48.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.255</text>\n",
       "<text text-anchor=\"middle\" x=\"59.95\" y=\"-34.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 40</text>\n",
       "<text text-anchor=\"middle\" x=\"59.95\" y=\"-20.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 6, 34]</text>\n",
       "<text text-anchor=\"middle\" x=\"59.95\" y=\"-6.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = class_2</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M135.02,-99.8C124.41,-90.36 113.06,-80.25 102.47,-70.84\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"104.72,-68.15 94.92,-64.12 100.07,-73.38 104.72,-68.15\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"#41e686\" stroke=\"black\" d=\"M245.86,-64C245.86,-64 150.05,-64 150.05,-64 144.05,-64 138.05,-58 138.05,-52 138.05,-52 138.05,-12 138.05,-12 138.05,-6 144.05,0 150.05,0 150.05,0 245.86,0 245.86,0 251.86,0 257.86,-6 257.86,-12 257.86,-12 257.86,-52 257.86,-52 257.86,-58 251.86,-64 245.86,-64\"/>\n",
       "<text text-anchor=\"middle\" x=\"197.95\" y=\"-48.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.075</text>\n",
       "<text text-anchor=\"middle\" x=\"197.95\" y=\"-34.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 51</text>\n",
       "<text text-anchor=\"middle\" x=\"197.95\" y=\"-20.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 49, 0]</text>\n",
       "<text text-anchor=\"middle\" x=\"197.95\" y=\"-6.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = class_1</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M185.23,-99.8C186.82,-91.46 188.51,-82.6 190.11,-74.15\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"193.59,-74.6 192.03,-64.12 186.72,-73.29 193.59,-74.6\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<path fill=\"#b388ef\" stroke=\"black\" d=\"M415.07,-64C415.07,-64 326.83,-64 326.83,-64 320.83,-64 314.83,-58 314.83,-52 314.83,-52 314.83,-12 314.83,-12 314.83,-6 320.83,0 326.83,0 326.83,0 415.07,0 415.07,0 421.07,0 427.07,-6 427.07,-12 427.07,-12 427.07,-52 427.07,-52 427.07,-58 421.07,-64 415.07,-64\"/>\n",
       "<text text-anchor=\"middle\" x=\"370.95\" y=\"-48.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.408</text>\n",
       "<text text-anchor=\"middle\" x=\"370.95\" y=\"-34.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 7</text>\n",
       "<text text-anchor=\"middle\" x=\"370.95\" y=\"-20.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2, 5]</text>\n",
       "<text text-anchor=\"middle\" x=\"370.95\" y=\"-6.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = class_2</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M383.04,-99.8C381.53,-91.46 379.93,-82.6 378.4,-74.15\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"381.81,-73.33 376.58,-64.12 374.92,-74.58 381.81,-73.33\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<path fill=\"#e6843e\" stroke=\"black\" d=\"M552.86,-64C552.86,-64 457.05,-64 457.05,-64 451.05,-64 445.05,-58 445.05,-52 445.05,-52 445.05,-12 445.05,-12 445.05,-6 451.05,0 457.05,0 457.05,0 552.86,0 552.86,0 558.86,0 564.86,-6 564.86,-12 564.86,-12 564.86,-52 564.86,-52 564.86,-58 558.86,-64 552.86,-64\"/>\n",
       "<text text-anchor=\"middle\" x=\"504.95\" y=\"-48.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.044</text>\n",
       "<text text-anchor=\"middle\" x=\"504.95\" y=\"-34.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 44</text>\n",
       "<text text-anchor=\"middle\" x=\"504.95\" y=\"-20.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [43, 1, 0]</text>\n",
       "<text text-anchor=\"middle\" x=\"504.95\" y=\"-6.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = class_0</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M431.8,-99.8C442.03,-90.45 452.98,-80.45 463.21,-71.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"465.85,-73.44 470.87,-64.12 461.13,-68.28 465.85,-73.44\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1a1f868358>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "dot_data = export_graphviz(classifier, out_file=None, feature_names=wine.feature_names, \n",
    "                           class_names=wine.target_names, filled=True,\n",
    "                           rounded=True, special_characters=False)\n",
    "graph = graphviz.Source(dot_data)\n",
    "#graph.render(\"wine\")\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MWsj9RxF_EQA"
   },
   "source": [
    "What rules can you find in the trees you have induced? Do they make sense?\n",
    "\n",
    "**Report:**\n",
    "1. How accurate are the decision tree classifiers for the two data sets? Look at overall accuracy as well as precision and recall for specific classes.\n",
    "2. How does training error relate to test error?\n",
    "3. Can you make sense of the rules implicit in the trees? Consider especially the pruned tree for the English past tense data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XjMATs49Sfpp"
   },
   "source": [
    "## K-Nearest Neighbor\n",
    "\n",
    "The third task is to use k-nearest neighbor classification to predict the plural form of a German noun and the past tense form of an English verb.\n",
    "\n",
    "The training part of a knn is simply storing all the training data points. However, for predicitng a class, all pairwise distances between the training and test set must be calculated. There are lots of ways of getting around this time consuming process. Here, you can simply randomly subsample the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "y9AtpjOGCnLb",
    "outputId": "62ef4c74-bb03-4f36-a1b6-aa8e56aa9112"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (14, 13) , y: (14,)\n",
      "[False False False False False False  True False False False False False\n",
      " False False False False  True False  True False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True False False False False False False False False False False False\n",
      " False False False False False False False  True False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True False False False False False  True False False False False  True\n",
      "  True False False False False False False False False False False False\n",
      "  True False False False False False False False False  True False False\n",
      " False False False False False False False False False False False False\n",
      " False False  True False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True False False False False False False False False False False\n",
      "  True False False False False False False False False False]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "I = np.random.uniform(0, 1, size=X.shape[0]) < .1\n",
    "X = X[I, :]\n",
    "y = y[I]\n",
    "print(\"X:\", X.shape, \", y:\", y.shape)\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hJOPyhFjDlk_"
   },
   "source": [
    "The classifier can be used as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "colab_type": "code",
    "id": "AxmcBs3gJ4Ri",
    "outputId": "2e70c905-2343-4986-bd3c-0154d3e18845"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.5, 0. ]),\n",
       " array([1., 0.]),\n",
       " array([0.66666667, 0.        ]),\n",
       " array([1, 1]))"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.9)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(y_test, knn.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lt3XV9kTIgE0"
   },
   "source": [
    "Compare training error to test error. Vary the number of neighbors used to predict the class and see how this affects training and test error. One of the properties of (simple) nearest neighbor classification is that all features are given equal weight, which means that irrelevant features could hurt classification accuracy. Check whether you can improve accuracy by removing features or reweighting samples. Compare the best accuracy to that obtained with decision trees.\n",
    "\n",
    "**Report:**\n",
    "1. How accurate are the nearest neighbor classifiers for the two data sets? Look at overall accuracy as well as precision and recall for specific classes.\n",
    "2. What is the effect of varying the k parameter? Plot the cross validated accuracy vs increasing k.\n",
    "3. Can you improve accuracy by removing less informative features?\n",
    "4. Does k-nearest neighbor perform better or worse than decision trees? Can you force the nearest neighbor classifier to behave like the pruned decision tree on the English past tense data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "utGge3LFSWVd"
   },
   "source": [
    "**Report:** Which features are most informative for the two data sets? Try to explain why some features are more informative than others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YdrPyjBuSps1"
   },
   "source": [
    "## VG assignment\n",
    "\n",
    "The above tasks are sufficient to obtain a pass grade (G) in this assignment. To obtain a pass with distinction (VG), all the assignments must be carried out without major errors, and there is an additional task you should solve.\n",
    "\n",
    "It is fairly obvious that the performance of a machine learning task depends on the amount of training data that is available, but the amount of data required to reach a certain level of performance in a specific task varies. Your last task is to relate the size of the training data to the performance you can achieve on the two data sets.\n",
    "\n",
    "Train your classifiers using the best hyperparameters you found for both prediction tasks on a varying amount of training data ranging from just a few examples to the full data set and test the resulting classifiers for each training set size. Do this for both types of classifiers (decision trees\n",
    "and kNN). Check if you can find a set of hyperparameters that work better for smaller training set size and compare the learning curves. Take a look at the rules in the decision trees for various training set sizes.\n",
    "\n",
    "**Report:** Describe how you ran these experiments and present the resulting learning curves, both in tabular and in graphical form. Report and discuss any interesting observations you made.\n",
    "\n",
    "# Submission\n",
    "\n",
    "You should submit one of the following two options:\n",
    "1. A written report (3-5 pages) in academic english, reporting and rguing for your conclusions on all tasks. All code must be included in an appentix and be well commented. The report should be submitted through Studentportalen.\n",
    "**OR**\n",
    "2. Your cleaned notebook with the relevant code and answers to all the questions. The ipynb-file should be submitted through Studentportalen. The code blocks should reproduce your main findings and be commented either in a text cell or standard code comments.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ML lab 1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
